<!DOCTYPE html>
<html lang="en-US" prefix="og: http://ogp.me/ns#">
<head >
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />

<!-- This site is optimized with the Yoast SEO plugin v9.2.1 - https://yoast.com/wordpress/plugins/seo/ -->
<title>Data Science Portfolio &mdash; Tim Dettmers</title>
<link rel="canonical" href="https://timdettmers.com/data-science-portfolio/" />
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Data Science Portfolio &mdash; Tim Dettmers" />
<meta property="og:description" content="This is my data science portfolio where I present some results from some hacks from hackathons and unpublished results from my previous research. Image Search for Fashion via Deep Autoencoder Abstract Here I scraped and preprocessed 420000 fashion images from several websites and trained RBMs which I unrolled into a deep autoencoder to find clothes &hellip;" />
<meta property="og:url" content="https://timdettmers.com/data-science-portfolio/" />
<meta property="og:site_name" content="Tim Dettmers" />
<meta property="article:publisher" content="https://www.facebook.com/people/Tim-Dettmers/100004739865154" />
<meta property="og:image" content="http://timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:description" content="This is my data science portfolio where I present some results from some hacks from hackathons and unpublished results from my previous research. Image Search for Fashion via Deep Autoencoder Abstract Here I scraped and preprocessed 420000 fashion images from several websites and trained RBMs which I unrolled into a deep autoencoder to find clothes [&hellip;]" />
<meta name="twitter:title" content="Data Science Portfolio &mdash; Tim Dettmers" />
<meta name="twitter:site" content="@Tim_Dettmers" />
<meta name="twitter:image" content="http://timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg" />
<meta name="twitter:creator" content="@Tim_dettmers" />
<script type='application/ld+json'>{"@context":"https:\/\/schema.org","@type":"Person","url":"https:\/\/timdettmers.com\/","sameAs":["https:\/\/www.facebook.com\/people\/Tim-Dettmers\/100004739865154","https:\/\/twitter.com\/Tim_Dettmers"],"@id":"#person","name":"Tim Dettmers"}</script>
<!-- / Yoast SEO plugin. -->

<link rel='dns-prefetch' href='//timdettmers.com' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//secure.gravatar.com' />
<link rel='dns-prefetch' href='//s.w.org' />
<link rel="alternate" type="application/rss+xml" title="Tim Dettmers &raquo; Feed" href="https://timdettmers.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Tim Dettmers &raquo; Comments Feed" href="https://timdettmers.com/comments/feed/" />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/11\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/11\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/timdettmers.com\/wp-includes\/js\/wp-emoji-release.min.js?ver=4.9.10"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55358,56760,9792,65039],[55358,56760,8203,9792,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel='stylesheet' id='child-theme-css'  href='https://timdettmers.com/wp-content/themes/genesis/style.css?ver=2.2.6' type='text/css' media='all' />
<link rel='stylesheet' id='tablepress-default-css'  href='https://timdettmers.com/wp-content/tablepress-combined.min.css?ver=3' type='text/css' media='all' />
<!--[if lte IE 8]>
<link rel='stylesheet' id='jetpack-carousel-ie8fix-css'  href='https://timdettmers.com/wp-content/plugins/jetpack/modules/carousel/jetpack-carousel-ie8fix.css?ver=20121024' type='text/css' media='all' />
<![endif]-->
<link rel='stylesheet' id='jetpack_css-css'  href='https://timdettmers.com/wp-content/plugins/jetpack/css/jetpack.css?ver=6.8' type='text/css' media='all' />
<script type='text/javascript' src='https://timdettmers.com/wp-includes/js/jquery/jquery.js?ver=1.12.4'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/themes/genesis/lib/js/skip-links.js?ver=4.9.10'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/jetpack/_inc/build/spin.min.js?ver=1.3'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/jetpack/_inc/build/jquery.spin.min.js?ver=1.3'></script>
<link rel='https://api.w.org/' href='https://timdettmers.com/wp-json/' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://timdettmers.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://timdettmers.com/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 4.9.10" />
<link rel='shortlink' href='https://wp.me/P7dUt6-6j' />
<link rel="alternate" type="application/json+oembed" href="https://timdettmers.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Ftimdettmers.com%2Fdata-science-portfolio%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://timdettmers.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Ftimdettmers.com%2Fdata-science-portfolio%2F&#038;format=xml" />

		<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
			ga('create', 'UA-68592625-1', 'auto');
			ga('send', 'pageview');
		</script>

	
<link rel='dns-prefetch' href='//v0.wordpress.com'/>
<link rel='dns-prefetch' href='//i0.wp.com'/>
<link rel='dns-prefetch' href='//i1.wp.com'/>
<link rel='dns-prefetch' href='//i2.wp.com'/>
<style type='text/css'>img#wpstats{display:none}</style><link rel="pingback" href="https://timdettmers.com/xmlrpc.php" />
<!--[if lt IE 9]><script src="https://timdettmers.com/wp-content/themes/genesis/lib/js/html5shiv.min.js"></script><![endif]-->
<style type="text/css">
/* <![CDATA[ */
img.latex { vertical-align: middle; border: none; }
/* ]]> */
</style>
<link rel="icon" href="https://i0.wp.com/timdettmers.com/wp-content/uploads/2018/05/cropped-profile_300kb.png?fit=32%2C32&#038;ssl=1" sizes="32x32" />
<link rel="icon" href="https://i0.wp.com/timdettmers.com/wp-content/uploads/2018/05/cropped-profile_300kb.png?fit=192%2C192&#038;ssl=1" sizes="192x192" />
<link rel="apple-touch-icon-precomposed" href="https://i0.wp.com/timdettmers.com/wp-content/uploads/2018/05/cropped-profile_300kb.png?fit=180%2C180&#038;ssl=1" />
<meta name="msapplication-TileImage" content="https://i0.wp.com/timdettmers.com/wp-content/uploads/2018/05/cropped-profile_300kb.png?fit=270%2C270&#038;ssl=1" />
</head>
<body class="page-template-default page page-id-391 nolayout" itemscope itemtype="http://schema.org/WebPage"><div class="site-container"><section><h2 class="screen-reader-text">Skip links</h2><ul class="genesis-skip-link"><li><a href="#genesis-nav-primary" class="screen-reader-shortcut"> Skip to primary navigation</a></li><li><a href="#genesis-content" class="screen-reader-shortcut"> Skip to content</a></li><li><a href="#genesis-sidebar-primary" class="screen-reader-shortcut"> Skip to primary sidebar</a></li></ul></section>
<header class="site-header" itemscope itemtype="http://schema.org/WPHeader"><div class="wrap"><div class="title-area"><p class="site-title" itemprop="headline"><a href="https://timdettmers.com/">Tim Dettmers</a></p><p class="site-description" itemprop="description">Making deep learning accessible.</p></div><div class="widget-area header-widget-area"><h2 class="genesis-sidebar-title screen-reader-text">Header Right</h2><section id="categories-4" class="widget widget_categories"><div class="widget-wrap"><h3 class="widgettitle widget-title">Blog Posts Topics</h3>
		<ul>
	<li class="cat-item cat-item-2"><a href="https://timdettmers.com/category/deep-learning/" >Deep Learning</a> (7)
</li>
	<li class="cat-item cat-item-25"><a href="https://timdettmers.com/category/featured/" >Featured</a> (1)
</li>
	<li class="cat-item cat-item-3"><a href="https://timdettmers.com/category/hardware/" >Hardware</a> (7)
</li>
	<li class="cat-item cat-item-4"><a href="https://timdettmers.com/category/neuroscience/" >Neuroscience</a> (1)
</li>
		</ul>
</div></section>
</div></div></header><h2 class="screen-reader-text">Main navigation</h2><nav class="nav-primary" itemscope itemtype="http://schema.org/SiteNavigationElement" id="genesis-nav-primary" aria-label="Main navigation"><div class="wrap"><ul id="menu-menu" class="menu genesis-nav-menu menu-primary js-superfish"><li id="menu-item-431" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-has-children menu-item-431"><a href="http://timdettmers.com" data-ps2id-api="true" itemprop="url"><span itemprop="name">Blog</span></a>
<ul class="sub-menu">
	<li id="menu-item-434" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-434"><a href="https://timdettmers.com/category/deep-learning/" data-ps2id-api="true" itemprop="url"><span itemprop="name">Deep Learning</span></a></li>
	<li id="menu-item-436" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-436"><a href="https://timdettmers.com/category/hardware/" data-ps2id-api="true" itemprop="url"><span itemprop="name">Hardware</span></a></li>
	<li id="menu-item-435" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-435"><a href="https://timdettmers.com/category/neuroscience/" data-ps2id-api="true" itemprop="url"><span itemprop="name">Neuroscience</span></a></li>
</ul>
</li>
<li id="menu-item-668" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-668"><a href="http://timdettmers.com/about/#Publications" data-ps2id-api="true" itemprop="url"><span itemprop="name">Publications</span></a></li>
<li id="menu-item-433" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-433"><a href="https://timdettmers.com/about/" data-ps2id-api="true" itemprop="url"><span itemprop="name">About Me</span></a></li>
</ul></div></nav><div class="site-inner"><div class="content-sidebar-wrap"><main class="content" id="genesis-content"><article class="post-391 page type-page status-publish entry" itemscope itemtype="http://schema.org/CreativeWork"><header class="entry-header"><h1 class="entry-title" itemprop="headline">Data Science Portfolio</h1> 
</header><div class="entry-content" itemprop="text"><p>This is my data science portfolio where I present some results from some hacks from hackathons and unpublished results from my previous research.</p>
<h1>Image Search for Fashion via Deep Autoencoder</h1>
<h3>Abstract</h3>
<p style="text-align: justify;">Here I scraped and preprocessed 420000 fashion images from several websites and trained RBMs which I unrolled into a deep autoencoder to find clothes which are similar to clothes in a given image. The results were reasonably good for images of clothes, but poor for cropped images of clothes worn by people.</p>
<h3>Methods</h3>
<p style="text-align: justify;">Images where scraped from several fashion websites and were preprocessed with a Sobel filter to learn the shape of the clothes instead of their color. Weights were pre-trained by stacking restricted Boltzmann machines (RBMs) which were unrolled into an autoencoder with a code layer of size 256 (architecture: 21000x2048x256x2048x21000). Similar images were then found by comparing the cosine similarity for all images. I used custom RBM and autoencoder implementations in python using gnumpy for GPU support.</p>
<h3>Results and discussion</h3>
<figure id="attachment_227" style="width: 773px" class="wp-caption alignnone"><a href="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg"><img data-attachment-id="227" data-permalink="https://timdettmers.com/2015/03/26/convolution-deep-learning/burdastyle/" data-orig-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg?fit=773%2C497&amp;ssl=1" data-orig-size="773,497" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="burdastyle" data-image-description="" data-medium-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg?fit=300%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg?fit=773%2C497&amp;ssl=1" class="wp-image-227 size-full" src="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/03/burdastyle.jpg?resize=773%2C497" alt="burdastyle" width="773" height="497" data-recalc-dims="1" /></a><figcaption class="wp-caption-text">Figure 1: Image search results obtained from the autoencoder codes. The top-left image is the search query, the other 9 images the most similar images measured by cosine similarity.</figcaption></figure>
<p>&nbsp;</p>
<p style="text-align: justify;">As seen in Figure 1 the autoencoder was sensitive to patterns (first image) and common details (clothes hangers in fourth image). The results were reasonably relevant with about 6-8 images of the same cloth category. The autoencoder codes did not incorporate fine details like the waistband on the mid-left dress in the third image. When used on cropped images of clothes worn by people, the results were poor (fifth image), as pose and orientation strongly influenced the results. More images or better preprocessing techniques would be needed to get reasonable results for such cropped images.</p>
<h1 style="text-align: justify;">Using Neural Word Embeddings for Food Pairing Suggestions</h1>
<h3 style="text-align: justify;">Abstract</h3>
<p style="text-align: justify;">A web-app was designed where users should receive suitable suggestions for adding a food ingredient to a number of already selected food ingredients. To generate these suggestions, I learned neural word embeddings (word2vec) on recipe data. The suggested ingredients fitted well with the already selected ingredients. However the suggestions via the word embeddings got quickly stuck in a particular cuisine, e.g. Mediterranean cuisine, and rare but working food pairings were never suggested.</p>
<h3 style="text-align: justify;">Methods</h3>
<p style="text-align: justify;">An open data recipe database of 50000 recipes was preprocessed so that it could be used with the word2vec tool to generate neural word embeddings. In the case of recipe data, which features much less smaller vocabulary with repetitive words, it was imperative to use a very small word window surrounding the central word (window size = 1) and penalize common words heavily, e.g. omit cases of tomato with high probability.</p>
<h3 style="text-align: justify;">Results and discussion</h3>
<figure id="attachment_392" style="width: 939px" class="wp-caption alignnone"><img data-attachment-id="392" data-permalink="https://timdettmers.com/data-science-portfolio/tsne_cluster/" data-orig-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_cluster.jpg?fit=939%2C687&amp;ssl=1" data-orig-size="939,687" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tSNE_cluster" data-image-description="" data-medium-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_cluster.jpg?fit=300%2C219&amp;ssl=1" data-large-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_cluster.jpg?fit=939%2C687&amp;ssl=1" class="wp-image-392 size-full" src="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_cluster.jpg?resize=939%2C687" alt="tSNE_cluster" width="939" height="687" data-recalc-dims="1" /><figcaption class="wp-caption-text">Figure 2: t-SNE plot of the word embedding cluster associated with the Mediterranean cuisine. Ingredients close to each other are similar or are commonly paired in recipes.</figcaption></figure>
<p>Using neural word embeddings created many distinct clusters for each regional cuisine as shown in Figure 2. This worked surprisingly well for this task even when the amount of the data was limited (about 250000 words). The resulting recommendations where quite good, so that a fitting ingredient could be found from two or more existing ingredients. However, when two or more ingredients were picked, most suggestions were only from the same cluster of regional cuisine and unusual pairings that work, like pineapple on pizza, were not suggested.</p>
<figure id="attachment_393" style="width: 1163px" class="wp-caption alignnone"><a href="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE.jpg"><img data-attachment-id="393" data-permalink="https://timdettmers.com/data-science-portfolio/tsne/" data-orig-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE.jpg?fit=1163%2C616&amp;ssl=1" data-orig-size="1163,616" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tSNE" data-image-description="" data-medium-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE.jpg?fit=300%2C159&amp;ssl=1" data-large-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE.jpg?fit=1024%2C542&amp;ssl=1" class="wp-image-393 size-full" src="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE.jpg?resize=1163%2C616" alt="tSNE" width="1163" height="616" data-recalc-dims="1" /></a><figcaption class="wp-caption-text">Figure 3: t-SNE plot of food ingredient word embeddings showing clusters for each cuisine. In green the Mediterranean cluster and in red the Mexican cluster.</figcaption></figure>
<p style="text-align: justify;"><a href="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_conditioned.jpg"><img data-attachment-id="394" data-permalink="https://timdettmers.com/data-science-portfolio/tsne_conditioned/" data-orig-file="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_conditioned.jpg?fit=1406%2C690&amp;ssl=1" data-orig-size="1406,690" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tSNE_conditioned" data-image-description="" data-medium-file="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_conditioned.jpg?fit=300%2C147&amp;ssl=1" data-large-file="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_conditioned.jpg?fit=1024%2C503&amp;ssl=1" class="wp-image-394 size-full" src="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/tSNE_conditioned.jpg?resize=1406%2C690" alt="tSNE_conditioned" width="1406" height="690" data-recalc-dims="1" /></a></p>
<p>Figure 4: t-SNE plot of word embeddings conditioned on Mexican cuisine. One can see that tomato moves out of the Mediterranean cluster and is now closer to food ingredients more distinct to the Mexican cuisine, e.g. bell pepper and kidney beans.</p>
<p style="text-align: justify;">From Figure 3 and 4 one can see, that conditioning on one ingredient or cuisine changes the constellation of the clusters in a reasonable way. When conditioned on the Mexican cuisine, some ingredients which are typical of both Mexican and other cuisines, e.g. tomatoes, move closer to the new Mexican cluster to reflect typical Mexican food pairings. However, in the case of tomato, the distance to the Mexican and Mediterranean cuisine is still about equal even after conditioning for Mexican cuisine. This shows that the neural network learned that tomatoes are prototypical for the Mediterranean cuisine.</p>
<h1>Finding Influencers on Twitter with Weighted PageRank</h1>
<h3 style="text-align: justify;">Abstract</h3>
<p style="text-align: justify;">The task was to find potential new bloggers for a news agency which are socially connected to existing bloggers on the news website. The Twitter social network of the existing bloggers was scraped and a weighted PageRank was calculated. With a analysis of conversations between existing bloggers and other twitter users, potentially influential new bloggers could be identified.</p>
<h3 style="text-align: justify;">Introduction</h3>
<p style="text-align: justify;">New bloggers should be found for a news agency who are influential in their field of work. Success of convincing these potential new bloggers to blog for the news agency was thought to be increased significantly if there was a social relationship with an existing blogger: &#8220;Hey, your friend is blogger for our news website, would you like to blog for us, too?&#8221;.</p>
<h3 style="text-align: justify;">Methods</h3>
<p style="text-align: justify;">The Twitter handles of the existing bloggers were scraped and 80 friends and followers were obtained via the Twitter API. Then 20 friends and followers of the friends and follows was obtained to build a social network. Due to the twitter rate limits. The total count of followers and friends for every twitter user was also obtained. A weighted PageRank was calculated with a weight of 1 for the scraped social network and each twitter user also received two additional nodes, with a single connection to that user with the weight equal being to the number of total followers and friends.</p>
<h3 style="text-align: justify;">Results</h3>
<p style="text-align: justify;"><img data-attachment-id="395" data-permalink="https://timdettmers.com/data-science-portfolio/huffpost/" data-orig-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/huffpost.jpg?fit=1150%2C465&amp;ssl=1" data-orig-size="1150,465" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="huffpost" data-image-description="" data-medium-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/huffpost.jpg?fit=300%2C121&amp;ssl=1" data-large-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/huffpost.jpg?fit=1024%2C414&amp;ssl=1" class="wp-image-395 size-full" src="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/huffpost.jpg?resize=1150%2C465" alt="huffpost" width="1150" height="465" data-recalc-dims="1" /></p>
<p>Screenshot of a table on the finished web-application. On can see that the influence in the network is marked by preferences of the initial bloggers as German twitter user often have larger PageRank than comparable US users.</p>
<h1 style="text-align: justify;">Improving Deep Learning Performance with Dropout Decay</h1>
<h3 style="text-align: justify;">Abstract</h3>
<p style="text-align: justify;">I took part in the Crowdflower Kaggle competition in which it was the task to predict weather labels (e.g. sunny, cloudy, cold, hot) from twitter data. I used a deep neural network with rectified linear units and placed 2nd. The data was preprocessed with regularized tf-idf. Dropout decay was used which greatly increased the performance of the model. The resulting model was superior to ensembles of linear and tree-based models and was comparable in performance to models that used additional feature engineering and specialized twitter tokenizers.</p>
<h3 style="text-align: justify;">Introduction</h3>
<p style="text-align: justify;">The task was it to predict how likely 24 different weather labels were for a given tweet, e.g. &#8220;Let&#8217;s hope all this nice weather doesn&#8217;t mean a rainy cold summer!&#8221;. The training data labels are grouped into three categories: Sentiment (e.g. negative, neutral), time of weather (e.g. future, past), type of weather (e.g. hot, snow).</p>
<h3 style="text-align: justify;">Methods</h3>
<p style="text-align: justify;">The data was preprocessed with tf-idf and the vocabulary was capped at 200000 words; stopwords were omitted. After using a single linear and three separate logistic regressions I found that linear regression was better and I optimized the parameters for that model. After that I limited the vocabulary to 9000 words and trained a deep neural network (DNN) with rectified linear units and 9000x2000x2000x24 architecture on the tf-idf data. Outputs were truncated to be in the <img src='https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='[0,1]' title='[0,1]' class='latex' /> range. The net was regularized with dropout in the inputs (0.2) and hidden layers (0.5) and training was accelerated by using Nesterov&#8217;s accelerated gradient. Once the cross validation error stagnated, dropout decay was used: Dropout was halved, the learning rate was decreased linearly after each epoch and momentum was dropped completely. Both models were ensembled by using a weighted averaged which was determined by using linear regression on the held out test data which was treated as cross validation set for the ensembling process.</p>
<h3 style="text-align: justify;">Results</h3>
<figure id="attachment_396" style="width: 1049px" class="wp-caption alignnone"><a href="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_crowdflower.png"><img data-attachment-id="396" data-permalink="https://timdettmers.com/data-science-portfolio/table_crowdflower/" data-orig-file="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_crowdflower.png?fit=1049%2C211&amp;ssl=1" data-orig-size="1049,211" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="table_crowdflower" data-image-description="" data-medium-file="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_crowdflower.png?fit=300%2C60&amp;ssl=1" data-large-file="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_crowdflower.png?fit=1024%2C206&amp;ssl=1" class="wp-image-396 size-full" src="https://i2.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_crowdflower.png?resize=1049%2C211" alt="table_crowdflower" width="1049" height="211" data-recalc-dims="1" /></a><figcaption class="wp-caption-text">Table 1: Methods used by the competition entries which ranked most highly. The most successful simple model was ridged regression (RR) which is linear regression with a L2 penalty. Random forest regression (RF) was found to slightly improve the overall performance in ensembles, but was often omitted in the final model to make it more simple.</figcaption></figure>
<p style="text-align: justify;">The DNN was weighted nine times stronger in the ensemble than the ridged regression (RR). This suggests that the DNN performed significantly better than a single RR. A ensemble of a DNN and RR performed equally well as multiple RRs with which model stacking was performed, i.e. the RRs feed into another RR together with the original tf-idf inputs.</p>
<p>However, a DNN with dropout decay outperformed the model stacking approach and was only bested by model stacking combined with additional feature engineering and a specialized twitter tokenizer (see Table 1). Thus dropout decay significantly increased performance. Rapid overfitting was observed when the learning rate was held steady after halving dropout, and similarly, no gains in performance occurred when the momentum was maintained after halving dropout. It was also observed, that dropout decay improved performance the most when the input dropout rate was high <img src='https://s0.wp.com/latex.php?latex=%280.2-0.3%29&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='(0.2-0.3)' title='(0.2-0.3)' class='latex' />, but hidden layer dropout rates made no impact on performance.</p>
<h3 style="text-align: justify;">Discussion</h3>
<p style="text-align: justify;">The results show that a deep neural network performs as well as simple algorithms which were trained on an elaborate set of hand-engineered features which included features from sentiment analysis, part of speech tagging and tf-idf features from a specialized twitter tokenizer.</p>
<p>Impressive was the decrease in root mean square test error after dropout decay was applied. However, poor results were obtained when learning rate was kept steady. A possible hypothesis for this behavior is, that the new information introduced into the network reveals a more accurate location of the local minima, which would otherwise be hidden in the induced variance of dropout. Because it is not likely, that the local minima of the training set is very close to a local minima of the cross validation set this also explains why a steady learning rate lead to rapid overfitting. Maintaining momentum probably lead to poor results because the momentum vector is composed of more noisy gradients which are adapted too slowly to the introduction of more precise location of local minima.</p>
<p>All in all, this work demonstrates that feature learning methods are on par with state of the art feature engineering. Large gains were observed after using dropout decay and this effect should be investigated in different circumstances to evaluate its significance.</p>
<h1 style="text-align: justify;">Improving Dense Neural Network Parallelism with RMSProp</h1>
<h3 style="text-align: justify;">Abstract</h3>
<p style="text-align: justify;">Parallelizing dense architectures is an inherently difficult problem due to communication bottlenecks. Here I show that such bottlenecks can be widened by using RMSProp, a technique that adjusts the learning rate for each weight. I demonstrate this technique by using a GPU cluster to learn word embeddings with hidden layer on the English Wikipedia corpus and obtain improved speedups with respect to networks which do not use RMSProp.</p>
<h3 style="text-align: justify;">Introduction</h3>
<p style="text-align: justify;">Efficient software exists (e.g. word2vec) that allows fast learning of word embeddings on large data sets, and these word embeddings do well on word similarity tasks. However, the word embeddings obtained in this way are shallow, i.e. no additional hidden layer is used in their computation. It was shown, that a learned hidden layer from a deep model could be used in many natural language tasks to achieve state-of-the-art performance. In this article, I developed a technique to speed up the learning of such deep models by using multiple GPUs. Here I show how RMSProp, a technique which modifies the learning rate for each weight, increases the speedup obtained from using multiple GPUs and also increases the learning relative to its computational costs. The current English Wikipedia dump was used to learn this model.</p>
<h3 style="text-align: justify;">Methods</h3>
<h4 style="text-align: justify;">Preprocessing</h4>
<p style="text-align: justify;">The latest Wikipedia XML dump was firstly tokenized into sentences using the Python NLTK library. Then each sentence with less than 5 words was discarded. Punctuation of the remaining sentences was removed and each sentence was cut into windows of 11 words with respect to a middle word (5 words before and after each respective word in the sentence). For each word slot which stretched beyond the boundaries of the window the word &#8220;padding&#8221; was used as a filler word. The top 100000 most common non-stop words were determined and assigned an index. Then all windows of words were traversed and replaced with their respective index for each word; rare words were replaces with an extra &#8220;rare-word-index&#8221;.</p>
<h4 style="text-align: justify;">Architecture</h4>
<p style="text-align: justify;">The architecture features a lookup table and a single hidden layer with ranking output function: The inputs were batches of word indexes which were fed into a lookup table layer that concatenated uniformly distributed initialized word vectors of size 64 to 256. This lookup table matrix was used as input to a hidden layer with non-linear activation function (sigmoid, or tanh). The next layer used linear output function with one-dimensional output and a ranking criterion. Each batch was fed twice through the network, once the original batch was used, the second time the same batch with middle word replaced by a random word was used. The following ranking criterion was then minimized which can be thought as increasing the geometric distance between the random word and other words in the window and decreasing it for all words within the original window:<br />
<a href="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq1.png"><img data-attachment-id="401" data-permalink="https://timdettmers.com/data-science-portfolio/eq1/" data-orig-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq1.png?fit=285%2C40&amp;ssl=1" data-orig-size="285,40" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="eq1" data-image-description="" data-medium-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq1.png?fit=285%2C40&amp;ssl=1" data-large-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq1.png?fit=285%2C40&amp;ssl=1" class="size-full wp-image-401 aligncenter" src="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq1.png?resize=285%2C40" alt="eq1" width="285" height="40" data-recalc-dims="1" /></a><br />
where <img src='https://s0.wp.com/latex.php?latex=x&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='x' title='x' class='latex' /> and <img src='https://s0.wp.com/latex.php?latex=x_%7B%5Cmbox%7Brdm%7D%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='x_{\mbox{rdm}}' title='x_{\mbox{rdm}}' class='latex' /> is the respective output of the linear output function of the network for the original word window or the original word window where the middle word is replaced by a random word.</p>
<h4 style="text-align: justify;">Implementation</h4>
<p style="text-align: justify;">Data parallelism was used to accelerate learning. This was done by splitting each batch into several sub-batches and then synchronizing gradients during the backpropagation pass. In the lookup table layer the gradients along their indexes for the words were used to synchronize the word embeddings. Nesterov&#8217;s accelerated gradient along with RMSProp was used. Nesterov&#8217;s accelerated gradient differs from classical momentum only in the timing of the update (1), which occurs before forward and backward propagation (2) and the weight updates (3):</p>
<p style="text-align: justify;"><a href="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq2.png"><img data-attachment-id="400" data-permalink="https://timdettmers.com/data-science-portfolio/eq2/" data-orig-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq2.png?fit=725%2C177&amp;ssl=1" data-orig-size="725,177" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="eq2" data-image-description="" data-medium-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq2.png?fit=300%2C73&amp;ssl=1" data-large-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq2.png?fit=725%2C177&amp;ssl=1" class="size-full wp-image-400 aligncenter" src="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq2.png?resize=725%2C177" alt="eq2" width="725" height="177" data-recalc-dims="1" /></a><br />
where <img src='https://s0.wp.com/latex.php?latex=w&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='w' title='w' class='latex' /> is the weight matrix, <img src='https://s0.wp.com/latex.php?latex=n&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='n' title='n' class='latex' /> the altered weight matrix used in forward propagation, <img src='https://s0.wp.com/latex.php?latex=m&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='m' title='m' class='latex' /> the momentum value [0,1], <img src='https://s0.wp.com/latex.php?latex=%5Calpha&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='\alpha' title='\alpha' class='latex' /> the learning rate and <img src='https://s0.wp.com/latex.php?latex=M&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='M' title='M' class='latex' /> the momentum matrix. Take note that the weight update <img src='https://s0.wp.com/latex.php?latex=w_%7Bt%2B1%7D%3Dn_t-%5Calpha+%5Cdfrac%7B%5Cpartial+E%7D%7B%5Cpartial+n_t%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='w_{t+1}=n_t-\alpha \dfrac{\partial E}{\partial n_t}' title='w_{t+1}=n_t-\alpha \dfrac{\partial E}{\partial n_t}' class='latex' /> is computationally more efficient. Nesterov&#8217;s accelerated gradient makes the momentum more stable which enables larger initial momentum rates and thus faster learning. RMSProp uses the root mean square of the weighted average of the accumulated gradient of the batches to normalize the current gradient, i.e. the current gradient is divided by the value of RMS<img src='https://s0.wp.com/latex.php?latex=_%7Bt%2B1%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='_{t+1}' title='_{t+1}' class='latex' />:</p>
<p style="text-align: justify;"><a href="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq3.png"><img data-attachment-id="399" data-permalink="https://timdettmers.com/data-science-portfolio/eq3/" data-orig-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq3.png?fit=450%2C77&amp;ssl=1" data-orig-size="450,77" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="eq3" data-image-description="" data-medium-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq3.png?fit=300%2C51&amp;ssl=1" data-large-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq3.png?fit=450%2C77&amp;ssl=1" class="size-full wp-image-399 aligncenter" src="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/eq3.png?resize=450%2C77" alt="eq3" width="450" height="77" data-recalc-dims="1" /></a></p>
<p>where <img src='https://s0.wp.com/latex.php?latex=%5Cdfrac%7B%5Cpartial+E%7D%7B%5Cpartial+n_t%7D&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='\dfrac{\partial E}{\partial n_t}' title='\dfrac{\partial E}{\partial n_t}' class='latex' /> is the gradient of the error with respect to the weight altered by the momentum update, and <img src='https://s0.wp.com/latex.php?latex=c&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='c' title='c' class='latex' /> is the weight of the of the current gradient in the weighted average; in this example <img src='https://s0.wp.com/latex.php?latex=c%3D0.8&#038;bg=ffffff&#038;fg=000000&#038;s=0' alt='c=0.8' title='c=0.8' class='latex' /> was used.</p>
<p>RMSProp prevents that individual weights which have small gradients suffer from too small learning rates &#8212; with RMSProp the learning rate is normalized, so that good word embeddings are learned quickly even for rare words. Another advantage is, that rare but large errors are amplified and thus learned from more quickly. RMSProp can speed up learning by a factor of about three and makes learning more stable, in that certain weights do not get stuck during learning. Another advantage of using RMSProp is that it is computationally expensive which improves the ratio for communication/computation. Communication that synchronizes gradients among networks can thus be partially hidden under RMSProp calculation.</p>
<h4 style="text-align: justify;">Hardware and software</h4>
<p style="text-align: justify;">Two nodes, i.e. computers, were used which were connected by a 40Gbit/s (5GB/s) Infiniband connection. The nodes had one and three GTX Titan GPUs, respectively. The minimal data transfer rate between GPUs within a node is 8GB/s. The Infiniband adapters where RDMA capable, which means that GPU buffers between nodes could be directly read and written from GPU to GPU not involving the CPU for conversion into a CPU buffer. This feature improved communication speed by roughly 15\% between nodes.</p>
<h3 style="text-align: justify;">Results</h3>
<p style="text-align: justify;">Table 2 shows the speedups obtained during training with and without RMSProp. One can see that using RMSProp and hiding gradient communication under its calculation improves the speedup obtained when using multiple GPUs. One can also see, that the speedup is little or even decreased for architectures that feature larger hidden layers. This is due to the fact that the communication between GPUs is the bottleneck during training and that the rather fast Infiniband connection is still too slow so that networks need to wait for gradient synchronizations to be finished until each net can proceed to the next forward pass. This is a general problem encountered in data parallelism for neural networks.</p>
<figure id="attachment_398" style="width: 1168px" class="wp-caption alignnone"><img data-attachment-id="398" data-permalink="https://timdettmers.com/data-science-portfolio/table_parallel/" data-orig-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_parallel.png?fit=1168%2C436&amp;ssl=1" data-orig-size="1168,436" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="table_parallel" data-image-description="" data-medium-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_parallel.png?fit=300%2C112&amp;ssl=1" data-large-file="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_parallel.png?fit=1024%2C382&amp;ssl=1" class="wp-image-398 size-full" src="https://i0.wp.com/timdettmers.com/wp-content/uploads/2015/10/table_parallel.png?resize=1168%2C436" alt="table_parallel" width="1168" height="436" data-recalc-dims="1" /><figcaption class="wp-caption-text">Table 2: Speedup with and without RMSProp with different word vector and hidder layer dimensions. One can see a big drop in speedup from one node (up to 3 GPUs) to two nodes (3 + 1 GPUs). In general RMSProp yields greater improvement the more GPUs are used.</figcaption></figure>
<p style="text-align: justify;">Besides the increased speedup, RMSProp accelerated the learning significantly. While the computation of RMSProp increased the time needed to pass through the data set by about 50\%, the same cross validation score was reached about three times faster. This effect comes mainly that gradients for rare errors that are proportionally large are amplified. This effect might be less sophisticated for rectified linear or activation functions which have steeper gradients in general.</p>
<figure id="attachment_397" style="width: 1427px" class="wp-caption alignnone"><a href="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/wikinet.png"><img data-attachment-id="397" data-permalink="https://timdettmers.com/data-science-portfolio/wikinet/" data-orig-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/wikinet.png?fit=1427%2C803&amp;ssl=1" data-orig-size="1427,803" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="wikinet" data-image-description="" data-medium-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/wikinet.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/wikinet.png?fit=1024%2C576&amp;ssl=1" class="wp-image-397 size-full" src="https://i1.wp.com/timdettmers.com/wp-content/uploads/2015/10/wikinet.png?resize=1427%2C803" alt="wikinet" width="1427" height="803" data-recalc-dims="1" /></a><figcaption class="wp-caption-text">Figure 6: t-SNE plot of word embeddings of some common words and their top 3 related words</figcaption></figure>
<h3>Discussion</h3>
<p>Here I showed that hiding gradient synchronization partially under RMSProp calculation yields speedups when using multiple GPUs for training dense neural networks. While RMSProp increases the calculation time by about 50\% it enables three times faster learning which is mainly because the weights of rare words are learned more quickly. The increase in computation time improves the computation/communication ratio which in turn improves speedups in parallelization where communication is the bottleneck. On the other hand, It was also found, that this techniques does not scale to large architectures or to multiple nodes in the network. Model parallelism or asynchronous techniques need to be developed for such cases. However, the technique presented here might be viable to parallelize recurrent neural networks which are very difficult to parallelize due to their long sequential nature and often dense connectivity. Hessian-free optimization would be ideal to apply the same technique as used in this article, as Hessian-free optimization is computationally expensive yet very powerful for recurrent neural networks.</p>
</div></article><h2 class="screen-reader-text">Reader Interactions</h2></main><aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar" itemscope itemtype="http://schema.org/WPSideBar" id="genesis-sidebar-primary"><h2 class="genesis-sidebar-title screen-reader-text">Primary Sidebar</h2><section id="blog_subscription-5" class="widget jetpack_subscription_widget"><div class="widget-wrap"><h3 class="widgettitle widget-title">Subscribe to Blog via Email</h3>

			<form action="#" method="post" accept-charset="utf-8" id="subscribe-blog-blog_subscription-5">
				<div id="subscribe-text"><p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
</div><p>Join 1,406 other subscribers</p>
					<p id="subscribe-email">
						<label id="jetpack-subscribe-label" for="subscribe-field-blog_subscription-5">
							Email Address						</label>
						<input type="email" name="email" required="required" class="required" value="" id="subscribe-field-blog_subscription-5" placeholder="Email Address" />
					</p>

					<p id="subscribe-submit">
						<input type="hidden" name="action" value="subscribe" />
						<input type="hidden" name="source" value="https://timdettmers.com/data-science-portfolio/" />
						<input type="hidden" name="sub-type" value="widget" />
						<input type="hidden" name="redirect_fragment" value="blog_subscription-5" />
												<input type="submit" value="Subscribe" name="jetpack_subscriptions_widget" />
					</p>
							</form>

			<script>
			/*
			Custom functionality for safari and IE
			 */
			(function( d ) {
				// In case the placeholder functionality is available we remove labels
				if ( ( 'placeholder' in d.createElement( 'input' ) ) ) {
					var label = d.querySelector( 'label[for=subscribe-field-blog_subscription-5]' );
						label.style.clip 	 = 'rect(1px, 1px, 1px, 1px)';
						label.style.position = 'absolute';
						label.style.height   = '1px';
						label.style.width    = '1px';
						label.style.overflow = 'hidden';
				}

				// Make sure the email value is filled in before allowing submit
				var form = d.getElementById('subscribe-blog-blog_subscription-5'),
					input = d.getElementById('subscribe-field-blog_subscription-5'),
					handler = function( event ) {
						if ( '' === input.value ) {
							input.focus();

							if ( event.preventDefault ){
								event.preventDefault();
							}

							return false;
						}
					};

				if ( window.addEventListener ) {
					form.addEventListener( 'submit', handler, false );
				} else {
					form.attachEvent( 'onsubmit', handler );
				}
			})( document );
			</script>
				
</div></section>
<section id="jetpack_display_posts_widget-3" class="widget widget_jetpack_display_posts_widget"><div class="widget-wrap"><h3 class="widgettitle widget-title">Recent Posts: Tim Dettmers</h3>
<div class="jetpack-display-remote-posts"><h4><a href="https://timdettmers.com/2019/04/03/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a></h4>
<h4><a href="https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/">A Full Hardware Guide to Deep Learning</a></h4>
<h4><a href="https://timdettmers.com/2018/11/26/phd-applications/">Machine Learning PhD Applications  Everything You Need to Know</a></h4>
<h4><a href="https://timdettmers.com/2018/10/17/tpus-vs-gpus-for-transformers-bert/">TPUs vs GPUs for Transformers (BERT)</a></h4>
<h4><a href="https://timdettmers.com/2017/12/21/deep-learning-hardware-limbo/">Deep Learning Hardware Limbo</a></h4>
<h4><a href="https://timdettmers.com/2017/09/16/credit-assignment-deep-learning/">Credit Assignment in Deep Learning</a></h4>
</div><!-- .jetpack-display-remote-posts --></div></section>
<section id="twitter_timeline-3" class="widget widget_twitter_timeline"><div class="widget-wrap"><a class="twitter-timeline" data-height="400" data-theme="light" data-link-color="#f96e5b" data-border-color="#e8e8e8" data-lang="EN" data-partner="jetpack" data-chrome="noheader nofooter noborders noscrollbar" href="https://twitter.com/@tim_dettmers" href="https://twitter.com/@tim_dettmers">My Tweets</a></div></section>
</aside></div><aside class="sidebar sidebar-secondary widget-area" role="complementary" aria-label="Secondary Sidebar" itemscope itemtype="http://schema.org/WPSideBar" id="genesis-sidebar-secondary"><h2 class="genesis-sidebar-title screen-reader-text">Secondary Sidebar</h2><section id="custom_html-3" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"></div></div></section>
</aside></div><footer class="site-footer" itemscope itemtype="http://schema.org/WPFooter"><div class="wrap"><p>Copyright &#x000A9;&nbsp;2019 &#x000B7;  <a href="http://www.studiopress.com/">Genesis Framework</a> &#x000B7; <a href="http://wordpress.org/">WordPress</a> &#x000B7; <a rel="nofollow" href="https://timdettmers.com/wp-login.php">Log in</a></p></div></footer></div>	<div style="display:none">
	</div>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/jetpack/_inc/build/photon/photon.min.js?ver=20130122'></script>
<script type='text/javascript' src='https://s0.wp.com/wp-content/js/devicepx-jetpack.js?ver=201917'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var mPS2id_params = {"instances":{"mPS2id_instance_0":{"selector":"a[rel='m_PageScroll2id']","autoSelectorMenuLinks":"true","scrollSpeed":200,"autoScrollSpeed":"true","scrollEasing":"easeInOutQuint","scrollingEasing":"easeOutQuint","pageEndSmoothScroll":"true","stopScrollOnUserAction":"false","autoCorrectScroll":"false","layout":"vertical","offset":"200","highlightSelector":"","clickedClass":"mPS2id-clicked","targetClass":"mPS2id-target","highlightClass":"mPS2id-highlight","forceSingleHighlight":"false","keepHighlightUntilNext":"false","highlightByNextTarget":"false","appendHash":"false","scrollToHash":"true","scrollToHashForAll":"true","scrollToHashDelay":0,"scrollToHashUseElementData":"true","scrollToHashRemoveUrlHash":"false","disablePluginBelow":0,"adminDisplayWidgetsId":"true","adminTinyMCEbuttons":"true","unbindUnrelatedClickEvents":"false","normalizeAnchorPointTargets":"false"}},"total_instances":"1","shortcode_class":"_ps2id"};
/* ]]> */
</script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/page-scroll-to-id/js/page-scroll-to-id.min.js?ver=1.6.3'></script>
<script type='text/javascript' src='https://secure.gravatar.com/js/gprofiles.js?ver=2019Apraa'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var WPGroHo = {"my_hash":""};
/* ]]> */
</script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/jetpack/modules/wpgroho.js?ver=4.9.10'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-includes/js/hoverIntent.min.js?ver=1.8.1'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/themes/genesis/lib/js/menu/superfish.min.js?ver=1.7.5'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/themes/genesis/lib/js/menu/superfish.args.min.js?ver=2.2.6'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/jetpack/_inc/build/twitter-timeline.min.js?ver=4.0.0'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var jetpackCarouselStrings = {"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/timdettmers.com\/wp-admin\/admin-ajax.php","nonce":"c942109c76","display_exif":"1","display_geo":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post Comment","write_comment":"Write a Comment...","loading_comments":"Loading Comments...","download_original":"View full size <span class=\"photo-size\">{0}<span class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please be sure to submit some text with your comment.","no_comment_email":"Please provide an email address to comment.","no_comment_author":"Please provide your name to comment.","comment_post_error":"Sorry, but there was an error posting your comment. Please try again later.","comment_approved":"Your comment was approved.","comment_unapproved":"Your comment is in moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter Speed","focal_length":"Focal Length","copyright":"Copyright","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/timdettmers.com\/wp-login.php?redirect_to=https%3A%2F%2Ftimdettmers.com%2Fdata-science-portfolio%2F","blog_id":"1","meta_data":["camera","aperture","shutter_speed","focal_length","copyright"],"local_comments_commenting_as":"<fieldset><label for=\"email\">Email (Required)<\/label> <input type=\"text\" name=\"email\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-email-field\" \/><\/fieldset><fieldset><label for=\"author\">Name (Required)<\/label> <input type=\"text\" name=\"author\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-author-field\" \/><\/fieldset><fieldset><label for=\"url\">Website<\/label> <input type=\"text\" name=\"url\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-url-field\" \/><\/fieldset>"};
/* ]]> */
</script>
<script type='text/javascript' src='https://timdettmers.com/wp-content/plugins/jetpack/_inc/build/carousel/jetpack-carousel.min.js?ver=20170209'></script>
<script type='text/javascript' src='https://timdettmers.com/wp-includes/js/wp-embed.min.js?ver=4.9.10'></script>
<script type='text/javascript' src='https://stats.wp.com/e-201917.js' async='async' defer='defer'></script>
<script type='text/javascript'>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:6.8',blog:'106749684',post:'391',tz:'-7',srv:'timdettmers.com'} ]);
	_stq.push([ 'clickTrackerInit', '106749684', '391' ]);
</script>
</body>
</html>

<!-- Dynamic page generated in 0.402 seconds. -->
<!-- Cached page generated by WP-Super-Cache on 2019-04-26 14:50:15 -->

<!-- super cache -->